{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdbf070",
   "metadata": {},
   "source": [
    "# NeMo ASR to ONNX Conversion for Triton Inference Server\n",
    "\n",
    "## NeMo ASR ONNX Export\n",
    "\n",
    "This notebook guides you step-by-step through converting a pretrained NeMo ASR model (`nvidia/stt_en_fastconformer_ctc_large`) into optimized ONNX format modules:\n",
    "\n",
    "- **Preprocessor**: converts audio signal to Mel Spectrogram\n",
    "- **ASR Acoustic Model**: generates logits from Mel Spectrogram\n",
    "- **CTC Decoder**: extracts text from logits (kept in PyTorch due to limitations)\n",
    "\n",
    "These modules are designed to be deployed independently using Triton Inference Server. Preprocessor and CTC decoder will use the PyTorch backend in Triton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fe90bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install git+https://github.com/NVIDIA/NeMo.git@v2.2.0rc3#egg=nemo_toolkit[asr]\n",
    "# !pip install onnxruntime-gpu==1.19.0 soundfile psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdb928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import nemo.collections.asr as nemo_asr\n",
    "from nemo.collections.asr.modules import AudioToMelSpectrogramPreprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86873e92",
   "metadata": {},
   "source": [
    "## Step 1: Download and Initialize ASR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bc7b97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-25 12:14:49 mixins:181] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-03-25 12:14:50 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-03-25 12:14:50 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-03-25 12:14:50 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-25 12:14:50 features:305] PADDING: 0\n",
      "[NeMo I 2025-03-25 12:14:52 save_restore_connector:275] Model EncDecCTCModelBPE was successfully restored from /root/.cache/huggingface/hub/models--nvidia--stt_en_fastconformer_ctc_large/snapshots/5a84a7a3bee8d9bd414c6719ddfea7bc723e3961/stt_en_fastconformer_ctc_large.nemo.\n"
     ]
    }
   ],
   "source": [
    "### Device cuda or cpu\n",
    "device = 'cuda'\n",
    "model_name = \"nvidia/stt_en_fastconformer_ctc_large\"\n",
    "asr_model = nemo_asr.models.EncDecHybridRNNTCTCBPEModel.from_pretrained(\n",
    "    model_name=model_name, map_location='cuda'\n",
    ")\n",
    "asr_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664b67d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-25 12:15:46--  https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav\n",
      "Resolving dldata-public.s3.us-east-2.amazonaws.com (dldata-public.s3.us-east-2.amazonaws.com)... 52.219.108.66, 52.219.176.138, 52.219.98.98, ...\n",
      "Connecting to dldata-public.s3.us-east-2.amazonaws.com (dldata-public.s3.us-east-2.amazonaws.com)|52.219.108.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 237964 (232K) [audio/wav]\n",
      "Saving to: ‘2086-149220-0033.wav’\n",
      "\n",
      "2086-149220-0033.wa 100%[===================>] 232.39K   185KB/s    in 1.3s    \n",
      "\n",
      "2025-03-25 12:15:48 (185 KB/s) - ‘2086-149220-0033.wav’ saved [237964/237964]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dldata-public.s3.us-east-2.amazonaws.com/2086-149220-0033.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d8bcb8",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessor Module\n",
    "Due to current limitations, we keep the Preprocessor as a PyTorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58006a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-03-25 12:26:53 features:305] PADDING: 16\n",
      "torch.Size([1, 80, 752]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "preprocessor = AudioToMelSpectrogramPreprocessor(features=80)\n",
    "preprocessor.to(device)\n",
    "\n",
    "# Test preprocessor\n",
    "audio, sr = sf.read('2086-149220-0033.wav')\n",
    "audio_array = np.array([audio])\n",
    "audio_signal = torch.from_numpy(audio_array).to(device)\n",
    "audio_signal_len = torch.tensor([audio_signal.shape[1]]).to(device)\n",
    "\n",
    "processed_signal, processed_signal_length = preprocessor(input_signal = audio_signal, \n",
    "                                                         length= audio_signal_len)\n",
    "print(processed_signal.shape, processed_signal_length.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f915498",
   "metadata": {},
   "source": [
    "## Step 3: Export ASR Acoustic Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c31c3257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceSTTRu(torch.nn.Module):\n",
    "    def __init__(self, model_inference):\n",
    "        super().__init__()\n",
    "        self.asr_model = model_inference\n",
    "\n",
    "    def forward(self, processed_signal):\n",
    "        return self.asr_model.forward_for_export(processed_signal)\n",
    "\n",
    "stt_module = InferenceSTTRu(asr_model)\n",
    "stt_module.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2160703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.onnx.export(\n",
    "        stt_module,\n",
    "        processed_signal,\n",
    "        'model.onnx',\n",
    "        export_params=True,\n",
    "        input_names=[\"signal\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"signal\": {0: \"batch_size\", 2: \"sequence_length\"},\n",
    "            \"output\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bf7766",
   "metadata": {},
   "source": [
    "## Step 4: CTC Decoder\n",
    "Due to current limitations, we keep the CTC decoder as a PyTorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9772dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model.decoding.strategy = 'greedy_batch'\n",
    "ctc_decoder = asr_model.decoding.ctc_decoder_predictions_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa5d88",
   "metadata": {},
   "source": [
    "## Step 5: ONNX Model Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18315400",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:33:29.550425027 [I:onnxruntime:, inference_session.cc:583 TraceSessionOptions] Session Options {  execution_mode:0 execution_order:DEFAULT enable_profiling:0 optimized_model_filepath:\"\" enable_mem_pattern:1 enable_mem_reuse:1 enable_cpu_mem_arena:1 profile_file_prefix:onnxruntime_profile_ session_logid: session_log_severity_level:1 session_log_verbosity_level:0 max_num_graph_transformation_steps:10 graph_optimization_level:3 intra_op_param:OrtThreadPoolParams { thread_pool_size: 12 auto_set_affinity: 0 allow_spinning: 1 dynamic_block_base_: 0 stack_size: 0 affinity_str:  set_denormal_as_zero: 0 } inter_op_param:OrtThreadPoolParams { thread_pool_size: 0 auto_set_affinity: 0 allow_spinning: 1 dynamic_block_base_: 0 stack_size: 0 affinity_str:  set_denormal_as_zero: 0 } use_per_session_threads:1 thread_pool_allow_spinning:1 use_deterministic_compute:0 config_options: {  } }\n",
      "2025-03-25 12:33:29.550521408 [I:onnxruntime:, inference_session.cc:491 ConstructorCommon] Creating and using per session threadpools since use_per_session_threads_ is true\n",
      "2025-03-25 12:33:29.550560519 [I:onnxruntime:, inference_session.cc:509 ConstructorCommon] Dynamic block base set to 0\n",
      "2025-03-25 12:33:29.847865723 [I:onnxruntime:, inference_session.cc:1661 Initialize] Initializing session.\n",
      "2025-03-25 12:33:29.847911819 [I:onnxruntime:, inference_session.cc:1698 Initialize] Adding default CPU execution provider.\n",
      "2025-03-25 12:33:29.848180847 [I:onnxruntime:, graph_partitioner.cc:898 InlineFunctionsAOT] This model does not have any local functions defined. AOT Inlining is not performed\n",
      "2025-03-25 12:33:29.849896988 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.852283325 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level1_RuleBasedTransformer modified: 1 with status: OK\n",
      "2025-03-25 12:33:29.873543577 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DoubleQDQPairsRemover modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.886885500 [I:onnxruntime:, constant_sharing.cc:248 ApplyImpl] Total shared scalar initializer count: 1237\n",
      "2025-03-25 12:33:29.887031608 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantSharing modified: 1 with status: OK\n",
      "2025-03-25 12:33:29.908925180 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CommonSubexpressionElimination modified: 1 with status: OK\n",
      "2025-03-25 12:33:29.930935527 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantFolding modified: 1 with status: OK\n",
      "2025-03-25 12:33:29.944608498 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.0/self_attn/Transpose_4_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944630289 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.0/self_attn/Slice_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944640905 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.0/self_attn/Reshape_4_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944651241 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.0/self_attn/Concat_4_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944661019 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.0/self_attn/ConstantOfShape_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944671355 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/Shape_5_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944681971 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/Shape_4_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944691749 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Transpose_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944711025 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Reshape_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944720803 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Concat_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944730302 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/ConstantOfShape_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944740359 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Constant_1_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944751254 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/self_attn/Constant_19_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944760473 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/self_attn/Constant_16_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944769971 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/self_attn/Constant_15_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944780867 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Constant_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944790644 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.16/self_attn/Constant_14_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944883394 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/Constant_13_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.944922505 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/layers.17/conv/depthwise_conv/Slice_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.946121540 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulAddFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.947078925 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ReshapeFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.947100436 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FreeDimensionOverrideTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.947730963 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQPropagationTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.948354506 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.948939777 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RocmBlasAltImpl modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.951873111 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer TransposeOptimizer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.952871283 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level1_RuleBasedTransformer modified: 1 with status: OK\n",
      "2025-03-25 12:33:29.966297016 [I:onnxruntime:, graph.cc:4201 CleanUnusedInitializersAndNodeArgs] Removing initializer '/ConstantOfShape_3_output_0'. It is no longer used by any node.\n",
      "2025-03-25 12:33:29.967503595 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DoubleQDQPairsRemover modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.970414301 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CommonSubexpressionElimination modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.971531482 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantFolding modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.972210060 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulAddFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.973114645 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ReshapeFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.973133083 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FreeDimensionOverrideTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.973773388 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQPropagationTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.974351115 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.974936385 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RocmBlasAltImpl modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.975864716 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level1_RuleBasedTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.976528488 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DoubleQDQPairsRemover modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.979359575 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer CommonSubexpressionElimination modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.980497150 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConstantFolding modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.981119855 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulAddFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.982038966 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ReshapeFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.982057684 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FreeDimensionOverrideTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.982723132 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQPropagationTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.983333545 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EnsureUniqueDQForNodeUnit modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.983955691 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer RocmBlasAltImpl modified: 0 with status: OK\n",
      "2025-03-25 12:33:29.985319552 [I:onnxruntime:, cuda_execution_provider.cc:2517 GetCapability] CUDA kernel not found in registries for Op type: Tile node name: /Tile\n",
      "2025-03-25 12:33:30.016431897 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level2_RuleBasedTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.018995072 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer TransposeOptimizer_CPUExecutionProvider modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.019628393 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.020538286 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.021159594 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.021869182 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulIntegerToFloatFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.022510045 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer DynamicQuantizeMatMulFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.023402338 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer ConvActivationFusion modified: 1 with status: OK\n",
      "2025-03-25 12:33:30.041902181 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GeluFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.042562601 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer LayerNormFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.043167706 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SimplifiedLayerNormFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.043746551 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer AttentionFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.044431554 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer EmbedLayerNormFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.045393967 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherSliceToSplitFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.046065841 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GatherToSliceFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.046844990 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatmulTransposeFusion modified: 0 with status: OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 12:33:30.047512114 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasGeluFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.048279810 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer SkipLayerNormFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.049007836 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer FastGeluFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.050179773 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QuickGeluFusion modified: 1 with status: OK\n",
      "2025-03-25 12:33:30.065821989 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasSoftmaxFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.066459221 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer BiasDropoutFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.067121876 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulScaleFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.067625012 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulActivationFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.068214752 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer MatMulNBitsFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.068767337 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQFinalCleanupTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.069294499 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer Level2_RuleBasedTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.069851274 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQS8ToU8Transformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.070600811 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer QDQSelectorActionTransformer modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.071136074 [I:onnxruntime:, graph_transformer.cc:15 Apply] GraphTransformer GemmActivationFusion modified: 0 with status: OK\n",
      "2025-03-25 12:33:30.071707656 [I:onnxruntime:, graph_transfo"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "import psutil\n",
    "\n",
    "session_options = onnxruntime.SessionOptions()\n",
    "session_options.intra_op_num_threads = psutil.cpu_count(logical=True)\n",
    "session_options.log_severity_level = 1\n",
    "providers = [\"CUDAExecutionProvider\"]  # Change to CUDA if GPU is available\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('model.onnx', session_options, providers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db195919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "well i don't wish to see it any more observed phoebe turning away her eyes it is certainly very like the old portrait\n"
     ]
    }
   ],
   "source": [
    "audio, sr = sf.read('2086-149220-0033.wav')\n",
    "\n",
    "audio_array = np.array([audio])\n",
    "audio_signal = torch.from_numpy(audio_array).to(device)\n",
    "audio_signal_len = torch.tensor([audio_signal.shape[1]]).to(device)\n",
    "\n",
    "processed_signal, processed_signal_length = preprocessor(input_signal = audio_signal, \n",
    "                                                         length= audio_signal_len)\n",
    "\n",
    "output = ort_session.run(None, {\"signal\": processed_signal.cpu().numpy()})\n",
    "\n",
    "pred_text = ctc_decoder(torch.from_numpy(output[0]))[0].text\n",
    "print(pred_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5397e5",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0db584b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"well i don't wish to see it any more observed phoebe turning away her eyes it is certainly very like the old portrait\",\n",
       " \"well i don't wish to see it any more observed phoebe turning away her eyes it is certainly very like the old portrait\")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, pred_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53eccc",
   "metadata": {},
   "source": [
    "## Performance Comparison\n",
    "\n",
    "Performance measured using %%timeit:\n",
    "\n",
    "- **Original PyTorch inference:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b3f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "text = asr_model.transcribe(['2086-149220-0033.wav'])[0].text\n",
    "\n",
    "### 96 ms ± 9.2 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8bb1ce",
   "metadata": {},
   "source": [
    "- **ONNX optimized inference:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 10 -r 10\n",
    "audio_array = np.array([audio])\n",
    "audio_signal = torch.from_numpy(audio_array).to(device)\n",
    "audio_signal_len = torch.tensor([audio_signal.shape[1]]).to(device)\n",
    "\n",
    "processed_signal, processed_signal_length = preprocessor(input_signal = audio_signal, \n",
    "                                                         length= audio_signal_len)\n",
    "\n",
    "output = ort_session.run(None, {\"signal\": processed_signal.cpu().numpy()})\n",
    "\n",
    "pred_text = ctc_decoder(torch.from_numpy(output[0]))[0].text\n",
    "\n",
    "### 16.7 ms ± 1.41 ms per loop (mean ± std. dev. of 10 runs, 10 loops each)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5975cd62",
   "metadata": {},
   "source": [
    "#### The optimized ONNX inference significantly outperforms the original PyTorch inference, delivering roughly **6x speed-up**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebde53",
   "metadata": {},
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
